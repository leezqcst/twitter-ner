{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the raw yelp file to a big list of reviews\n",
    "from json import loads\n",
    "\n",
    "def yelpfeed_to_reviews(in_fname, out_fname):\n",
    "    with open(in_fname, 'r') as f:\n",
    "        with open(out_fname, 'w') as g:\n",
    "            for i, line in enumerate(f):\n",
    "                try:\n",
    "                    print '\\r{}'.format(i),\n",
    "                    data = loads(line)\n",
    "                    for review in data['reviews']:\n",
    "                        g.write(review['text']+'\\n')\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "yelpfeed_to_reviews('../data/yelp_businesses.json', '../data/yelp_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twokenize import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bring in all tweets training data and format as sentences\n",
    "data_fname = '../wnut_ner_evaluation/data/train_notypes'\n",
    "xs, ys = [], []\n",
    "with open(data_fname, 'r') as f:\n",
    "    x, y = [], []\n",
    "    for i, line in enumerate(f):\n",
    "        split = line.split()\n",
    "        if split:\n",
    "            x.append(split[0])\n",
    "            y.append(split[1])\n",
    "        else: \n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "            x, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2527752\n"
     ]
    }
   ],
   "source": [
    "# bring in all of the raw yelp reviews\n",
    "# tokenize them all with twokenize\n",
    "# convert them to sentences and add to the data\n",
    "for i, line in enumerate(open('../data/yelp_reviews', 'r')):\n",
    "    print '\\r{}'.format(i),\n",
    "    x = tokenize(line)\n",
    "    if x:\n",
    "        xs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" A convenience vocabulary wrapper \"\"\"\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "class Vocab():\n",
    "    def __init__(self, all_tokens=None, min_count=5):\n",
    "        self.min_count=min_count\n",
    "        self.count_index = Counter()\n",
    "        self._vocab2idx = {'<PAD>':0,\n",
    "                           '<UNK>':1}\n",
    "        self._idx2vocab = {0:'<PAD>',\n",
    "                           1:'<UNK>'}\n",
    "        self.vocabset = set(self._vocab2idx.keys())\n",
    "        self.idxset = set(self._idx2vocab.keys())\n",
    "        \n",
    "        if all_tokens:\n",
    "            self.use(all_tokens)\n",
    "\n",
    "        self._n = sum( count for count in self.count_index.values() if count >= self.min_count)\n",
    "        self._v = sum( 1 for count in self.count_index.values() if count >= self.min_count)\n",
    "\n",
    "        self.make_sampling_table()\n",
    "        \n",
    "    @property\n",
    "    def n(self):\n",
    "        return self._n    \n",
    "\n",
    "    @property\n",
    "    def v(self):\n",
    "        return self._v\n",
    "\n",
    "    @property\n",
    "    def pad(self):\n",
    "        return '<PAD>'\n",
    "    \n",
    "    @property\n",
    "    def ipad(self):\n",
    "        return 0\n",
    "    \n",
    "    def idx(self, token):\n",
    "        if token in self.vocabset:\n",
    "            return self._vocab2idx[token]\n",
    "        else:\n",
    "            return self._vocab2idx['<UNK>']\n",
    "        \n",
    "    def token(self, idx):\n",
    "        if idx in self.idxset:\n",
    "            return self._idx2vocab[idx]\n",
    "        else:\n",
    "            return self._idx2vocab['<UNK>']\n",
    "    \n",
    "    def use(self, tokens):\n",
    "        self.count_index = Counter()\n",
    "        self.add(tokens)        \n",
    "    \n",
    "    def add(self, tokens):\n",
    "        for token in tokens:\n",
    "            self.count_index[token] += 1\n",
    "        self._vocab2idx = {'<UNK>':0}\n",
    "        self._vocab2idx.update({token:i+1 for i, (token, count) in enumerate(self.count_index.most_common())\n",
    "                                if count >= self.min_count})\n",
    "        self._idx2vocab = {i:token for token, i in self._vocab2idx.items()}\n",
    "        self.vocabset = set(self._vocab2idx.keys())\n",
    "        self.idxset = set(self._idx2vocab.keys())\n",
    "        self._n = sum( count for count in self.count_index.values() if count >= self.min_count)\n",
    "        self._v = sum( 1 for count in self.count_index.values() if count >= self.min_count)\n",
    "        \n",
    "    def count(self, token):\n",
    "        return self.count_index[token]\n",
    "\n",
    "    def make_sampling_table(self, power_scalar=.75):\n",
    "        # from 0 to V-1, get the frequency\n",
    "        self.vocab_distribution = np.array([ (self.count_index[self._idx2vocab[idx]]/float(self._n))**power_scalar\n",
    "                                    for idx in range(len(self.idxset))])\n",
    "        self.vocab_distribution /= np.sum(self.vocab_distribution)\n",
    "\n",
    "    def sample(self, sample_shape):\n",
    "        # sample a tensor of indices\n",
    "        # by walking up the CDF\n",
    "        # setting each position to the index\n",
    "        # of the word which is the closest\n",
    "        # word with that CDF\n",
    "        sums = np.zeros(sample_shape)\n",
    "        rands = npr.uniform(size=sample_shape)\n",
    "        idxs = np.zeros(sample_shape)\n",
    "        for i in range(len(self.vocab_distribution)):\n",
    "            sums += self.vocab_distribution[i]\n",
    "            new = sums <= rands\n",
    "            if np.any(new):\n",
    "                idxs[new] = i\n",
    "            else:\n",
    "                break\n",
    "        return idxs.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tokens = ( word for x in xs for word in x )\n",
    "vocab = Vocab(all_tokens, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86077\n"
     ]
    }
   ],
   "source": [
    "print vocab.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFkCAYAAAAKf8APAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmdY0CRJEmdY0CRJEmd838AWd3kOz4E0VQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d9df3e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(vocab.count_index.values()), 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_to_sequence(sentence, vocab):\n",
    "    return [ vocab.token(token) for token in sentence ]\n",
    "\n",
    "def indices_to_sequences(sentences, vocab):\n",
    "    return [ index_to_sequence(sentence, vocab) for sentence in sentences ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from preprocess import *\n",
    "# all_chargrams = ( c for x in xs for g in chargrams(x) for c in g )\n",
    "# xvocab = Vocab(all_chargrams, min_count=5)\n",
    "# print xvocab.v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop any words not in vocab\n",
    "import numpy.random as npr\n",
    "small_xs = [ [ word for word in x if word in vocab.vocabset ] for x in npr.choice(xs, 5000, replace=False) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "n = 3\n",
    "targets, pos = [], []\n",
    "for a, x in enumerate(small_xs):\n",
    "    print '\\r{}'.format(a),\n",
    "    L = len(x)\n",
    "    for i in range(L):\n",
    "        for j in range(1,k+1):\n",
    "            if i-j >= 0:\n",
    "                targets.append(x[i])\n",
    "                pos.append(x[i-j])\n",
    "            if i+j < L:\n",
    "                targets.append(x[i])\n",
    "                pos.append(x[i+j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2cd69a5ad7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-90041fa5368a>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_distribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0msums\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_distribution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msums\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples = vocab.sample([len(targets), n]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = npr.choice(np.arange(len(vocab.vocab_distribution)), \n",
    "                     p=vocab.vocab_distribution,\n",
    "                     size=[len(targets), n]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342150\n"
     ]
    }
   ],
   "source": [
    "print len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negs = indices_to_sequences(samples, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342150 1342150 1342150\n"
     ]
    }
   ],
   "source": [
    "print len(targets), len(pos), len(negs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This place MUCH not We\n",
      "This has with available Swiss\n",
      "This some in tso's Always\n",
      "place This sushis If Hahahaha\n",
      "place has laughing were special\n",
      "place some trader t-t .\n",
      "place to ( Lover's restaurant\n",
      "has place looked speak cheap\n",
      "has some ink I She\n",
      "has This problem anybody's while\n"
     ]
    }
   ],
   "source": [
    "with open('skipgrams.txt', 'w') as f:\n",
    "    for i, (t,p, n) in enumerate(zip(targets, pos, negs)):\n",
    "        s = \" \".join([t]+[p]+n)\n",
    "        if i < 10:\n",
    "            print s\n",
    "        f.write(s+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tfmodel import *\n",
    "\n",
    "class Word2Vec(TFModel):\n",
    "    def build_forward(self):\n",
    "        self.word = tf.placeholder(tf.int32, [None])\n",
    "        self.pos = tf.placeholder(tf.int32, [None])\n",
    "        self.negs = [ tf.placeholder(tf.int32, [None]) for _ in xrange(self.n_neg) ]\n",
    "        \n",
    "        self.word_vectors = tf.Variable(tf.random_uniform([self.vocab.v, self.word_embed_size],\n",
    "                                                          -.1, .1, tf.float32))\n",
    "        self.context_vectors = tf.Variable(tf.random_uniform([self.vocab.v, self.word_embed_size],\n",
    "                                                          -.1, .1, tf.float32))\n",
    "        \n",
    "        self.embedded_word = tf.nn.embedding_lookup(self.word_vectors, self.word)\n",
    "        self.embedded_pos = tf.nn.embedding_lookup(self.context_vectors, self.pos)\n",
    "        self.embedded_negs = [ tf.nn.embedding_lookup(self.context_vectors, neg) for neg in self.negs ]\n",
    "        \n",
    "    def build_loss(self):\n",
    "        pos_loss = tf.nn.sigmoid(tf.reduce_sum(self.embedded_word * self.embedded_pos, [1]))\n",
    "        neg_loss = (1./self.n_neg) * tf.add_n([\n",
    "                tf.nn.sigmoid(-tf.reduce_sum(self.embedded_word * neg, [1]))\n",
    "                for neg in self.embedded_negs])\n",
    "        self.loss = tf.reduce_mean(pos_loss + neg_loss)\n",
    "        \n",
    "    def build_optimizer(self):\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "    def partial_fit(self, x, y, measure_only=False):\n",
    "        pos, negs = zip(*y)\n",
    "        feed_dict = {\n",
    "            self.word:x,\n",
    "            self.pos:pos\n",
    "        }\n",
    "        feed_dict.update({neg:n for neg,n in zip(self.negs, negs[0])})\n",
    "        if measure_only:\n",
    "            loss = self.session.run(self.loss, feed_dict)\n",
    "        else:\n",
    "            loss, _ = self.session.run([self.loss, self.train_op], feed_dict)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, x):\n",
    "        pass\n",
    "    \n",
    "    def save_vectors(self, fname):\n",
    "        vectors = self.session.run(self.word_vectors)\n",
    "        with open(fname, 'w') as f:\n",
    "            for i in xrange(self.vocab.v):\n",
    "                vec = vectors[i].tolist()\n",
    "                word = self.vocab.token(i)\n",
    "                f.write(' '.join([word]+vec)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loading... Done\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "params = {\n",
    "    'vocab':vocab,\n",
    "    'n_neg':3,\n",
    "    'learning_rate':.001,\n",
    "    'word_embed_size':50\n",
    "}\n",
    "\n",
    "w2v = Word2Vec(session, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = sequence_to_index(targets, vocab)\n",
    "py = sequence_to_index(pos, vocab)\n",
    "ny = sequences_to_indices(negs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4540, 27, 78]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny[:2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4540, 27, 78]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(py, zip(ny))[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_3' with dtype int32\n\t [[Node: Placeholder_3 = Placeholder[dtype=DT_INT32, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Placeholder_3', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-61-3e018dc09eca>\", line 11, in <module>\n    w2v = Word2Vec(session, **params)\n  File \"tfmodel.py\", line 14, in __init__\n    self.build_forward()\n  File \"<ipython-input-60-29327765614b>\", line 7, in build_forward\n    self.negs = [ tf.placeholder(tf.int32, [None]) for _ in xrange(self.n_neg) ]\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1212, in placeholder\n    name=name)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1530, in _placeholder\n    name=name)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-ea654aea7d40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomaseffland/Development/twitter-ner/notebooks/tfmodel.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, n_epoch, batch_size, **partial_fit_kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-29327765614b>\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, x, y, measure_only)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_3' with dtype int32\n\t [[Node: Placeholder_3 = Placeholder[dtype=DT_INT32, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Placeholder_3', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-61-3e018dc09eca>\", line 11, in <module>\n    w2v = Word2Vec(session, **params)\n  File \"tfmodel.py\", line 14, in __init__\n    self.build_forward()\n  File \"<ipython-input-60-29327765614b>\", line 7, in build_forward\n    self.negs = [ tf.placeholder(tf.int32, [None]) for _ in xrange(self.n_neg) ]\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1212, in placeholder\n    name=name)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1530, in _placeholder\n    name=name)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/thomaseffland/.virtualenvs/twitter/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "w2v.fit(x, zip(py, zip(ny)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
