{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Embedding Approaches for IE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "---\n",
    "\n",
    "Informal overview of a couple embedding approaches in IE\n",
    "\n",
    "1. Word embedding approaches - Motivation: NER for Social Media\n",
    "    * word2vec\n",
    "    * bag o' character n-grams\n",
    "    * expensive things\n",
    "2. Sequence embedding approaches - Motivation: Relation Classification\n",
    "3. Joint approaches -- End-to-end Relation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NER for Social Media -- word2vec\n",
    "---\n",
    "Skipgram objective:\n",
    "$ max \\ P(c_j = y | w_i ) \\ \\forall c_i \\in Context(w_i) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$where \\ \\ P(c_j = y | w_i ) = \\frac{exp(v(y)^T v(w_i))} { \\Sigma_{y'}{exp(v(y')^T v(w_i))}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Every word, every context has its own vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Words with similar contexts end up close together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some issues: \n",
    "   * Large vocabulary sizes\n",
    "   * Cannot handle new words\n",
    "   * Rare words will either be omitted or not learned well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# NER for Social Media -- bag of char-grams\n",
    "---\n",
    "Split up every word into a bag of character-grams, say 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`banana -> ['__b', '_ba', 'ban', 'ana', 'nan, 'ana' ,'na_', 'a__'] `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now $ v(w) = \\Sigma_i {v(c_{i-1:i+1})} \\ \\ \\forall c_i \\in \\ Characters(w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* More compact set of parameters\n",
    "* Can handle new words\n",
    "* Rare words can share parameters (but rare char-grams won't be learned well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# NER for Social Media -- fancy stuff\n",
    "---\n",
    "Could also think of other more heavily parameterized word embeddings..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Character Convolutions ... Gated Convolutions ...\n",
    "2. Character RNNs... LSTMs ... Bidirectional LSTMs ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**NOTE:** Will be slow at training time, and potentially need more data\n",
    "\n",
    "(In practice these reps can be cached for most character sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Relation Classification -- dependency path embeddings\n",
    "---\n",
    "Given a subject and object of a potential relation, classify if it is and if so, which type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Variable length sequences => sequence model (eg, RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Shortest path on the dependency tree (SDP) between subject (x) and object (y) often signals the relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let $\\ f(w_{1:n}) = RNN( w_1, ..., w_n ).hidden[n] \\ \\ where \\ \\ w_{1:n} = SDP(x, y) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then can train relation classification (supervised) with \n",
    "\n",
    "$ max \\ P(r(x,y)= y\\  | \\ x, y, w_{1:n})$\n",
    "\n",
    "$ where\\  P(r(x,y)| \\ x, y, w_{1:n}) =  softmax(\\ [v(x);\\ v(y);\\ f(w_{1:n})]^TW + b\\ ) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Joint NER and Relation Classification\n",
    "---\n",
    "* Would like to learn a system that classifies entities and their relations jointly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Everything is differentiable and can be trained via backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* So can plug in NER approach for use in Relation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**NOTE:** Errors propogate both ways -- want to use training signals at lower layers\n",
    "\n",
    "-> Jointly training multiple objectives (multitask) or layer-wise pretraining\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thanks!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
